{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who is heading for Diabetes?\n",
    "\n",
    "This is the predictive part of the 2017 Melbourne Datathon.\n",
    "\n",
    "The task is to predict the probability that a patient will be dispensed a drug related to Diabetes post 2015. This is quite important research as it will be an early warning system for doctors so intervention can potentially be made before it is too late.\n",
    "\n",
    "Use the patients that we have provided all the records for to build your model, then see how it performs on these unseen people.\n",
    "\n",
    "For patient ID'S 279,201 to 558,352 you need to submit a file with 2 columns, the Patient_ID and the probability in the range [0-1]. The file will have 279,153 rows including the header row. An example submission file is provided for download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data retrieval functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"../../sql/datasci.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def patient_data(connection, patient_id):\n",
    "    \"\"\"\n",
    "    Return the patient data.\n",
    "    \"\"\"\n",
    "    SQL = \"\"\"\n",
    "SELECT *\n",
    "FROM transactions a\n",
    "LEFT OUTER JOIN ChronicIllness_LookUp b \n",
    "    ON a.Drug_ID = b.MasterProductID \n",
    "LEFT OUTER JOIN patients c\n",
    "    ON a.Patient_ID = c.Patient_ID\n",
    "LEFT OUTER JOIN classification d\n",
    "    ON a.Patient_ID = d.Patient_ID\n",
    "LEFT OUTER JOIN social e\n",
    "    ON c.postcode = e.postcode\n",
    "WHERE a.Patient_ID = {}\n",
    "AND a.prescription_week < '2016-01-01'\n",
    "ORDER BY prescription_week\n",
    "    \"\"\".format(patient_id)\n",
    "\n",
    "    return pd.read_sql_query(SQL, connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction functions\n",
    "\n",
    "TODO: Update the SQL to do the cleaning so that the functions don't need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gender_map = {'F': 1, 'M': 0, 'U': 0.5}\n",
    "\n",
    "def gender(patient_data):\n",
    "    return gender_map[patient_data.gender[0]]\n",
    "\n",
    "def age(patient_data):\n",
    "    patient_age = 2016 - patient_data.year_of_birth[0]\n",
    "    if patient_age > 100: \n",
    "        return 50 \n",
    "    else: \n",
    "        return patient_age\n",
    "\n",
    "def socio_score(patient_data):\n",
    "    score = patient_data.disadvantage_score[0]\n",
    "    if isinstance(score, str):\n",
    "        return 1000\n",
    "    if score is None:\n",
    "        return 1000\n",
    "    return float(score)\n",
    "\n",
    "def had_diabetes(patient_data):\n",
    "    return float(patient_data.ChronicIllness.str.contains('Diabetes').any())\n",
    "\n",
    "def had_lipids(patient_data):\n",
    "    return float(patient_data.ChronicIllness.str.contains('Lipids').any())\n",
    "\n",
    "def had_hypertension(patient_data):\n",
    "    return float(patient_data.ChronicIllness.str.contains('Hypertension').any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute some basic features of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_extract(patient_frame):\n",
    "    \"\"\"\n",
    "    The thing that forms a feature vector.\n",
    "    \n",
    "    ** Make sure to partition out data from the 2016 period.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    x = [gender(patient_frame), \n",
    "         age(patient_frame), \n",
    "         socio_score(patient_frame),\n",
    "         had_diabetes(patient_frame),\n",
    "         had_lipids(patient_frame),\n",
    "         had_hypertension(patient_frame)]\n",
    "    \n",
    "    y = patient_frame.Target[0]\n",
    "    \n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the matrix of features and vector of targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137ac5bd77444026a77fb4f064f3a485"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n = 20000\n",
    "\n",
    "X, Y = [], []\n",
    "for i in tqdm.tqdm_notebook(np.random.randint(0, 279201, n)): \n",
    "    x, y = feature_extract(patient_data(conn, i))\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "    \n",
    "X = np.vstack(X)\n",
    "y = np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out a set of different classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the feature matrix is usually transformed to have zero mean and unit standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition the data into test and train datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Random Forrest\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.95      0.95      8216\n",
      "          1       0.76      0.72      0.74      1784\n",
      "\n",
      "avg / total       0.91      0.91      0.91     10000\n",
      "\n",
      "Classifier: Decision Tree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.95      0.94      8216\n",
      "          1       0.76      0.67      0.71      1784\n",
      "\n",
      "avg / total       0.90      0.90      0.90     10000\n",
      "\n",
      "Classifier: Adaboost\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.93      0.96      8216\n",
      "          1       0.75      0.94      0.83      1784\n",
      "\n",
      "avg / total       0.94      0.93      0.94     10000\n",
      "\n",
      "Classifier: SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.93      0.96      8216\n",
      "          1       0.75      0.94      0.83      1784\n",
      "\n",
      "avg / total       0.94      0.93      0.94     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    ('Random Forrest', RandomForestClassifier()),\n",
    "    ('Decision Tree', DecisionTreeClassifier()),\n",
    "    ('Adaboost',AdaBoostClassifier() ),\n",
    "    ('SVM',SVC(probability=True))]\n",
    "\n",
    "for name, clf in classifiers:\n",
    "    print('Classifier: {}'.format(name))\n",
    "    model = clf.fit(X_train, y_train)\n",
    "    y_true, y_pred = y_test, clf.predict(X_test) \n",
    "    print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Form a submission\n",
    "\n",
    "Perform the prediction in 1000 patient \"chunks\" to speed up the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../../submissions/diabetes_submission_example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "chunks = submission.groupby(np.arange(len(submission)) // 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a164e1827b124b90a135693e6e08c314"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for group, frame in tqdm.tqdm_notebook(chunks):\n",
    "    \n",
    "    # Extract the features\n",
    "    data = [feature_extract(patient_data(conn, x)) for x in frame.Patient_ID.values]\n",
    "    \n",
    "    # Construct prediction X matrix\n",
    "    pred_x = np.vstack([x[0] for x in data])\n",
    "    \n",
    "    # Make sure we don't have nans in the data\n",
    "    pred_x[np.isnan(pred_x)] = 0\n",
    "    \n",
    "    # Apply the standard transform prior to fitting. \n",
    "    pred_x = StandardScaler().fit_transform(pred_x)\n",
    "    \n",
    "    # Fit the model\n",
    "    submission.Diabetes[frame.index] = clf.predict_proba(pred_x)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('../../submissions/kaggle.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
